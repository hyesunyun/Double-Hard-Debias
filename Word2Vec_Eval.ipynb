{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Double-Hard Debias: Tailoring Word Embeddings for Gender Bias Mitigation](https://arxiv.org/abs/2005.00965)\n",
    "\n",
    "For more detailed explanations, please refer to the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import codecs\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import scipy\n",
    "import codecs, os, json\n",
    "import operator\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def normalize(wv):\n",
    "    \n",
    "    # normalize vectors\n",
    "    norms = np.apply_along_axis(LA.norm, 1, wv)\n",
    "    wv = wv / norms[:, np.newaxis]\n",
    "    return wv\n",
    "\n",
    "def load_w2v(file_path):\n",
    "    model =gensim.models.KeyedVectors.load_word2vec_format(file_path, binary=True)\n",
    "    vocab = sorted([w for w in model.vocab], key=lambda w: model.vocab[w].index)\n",
    "    w2i = {w: i for i, w in enumerate(vocab)}\n",
    "    wv = [model[w] for w in vocab]\n",
    "    wv = np.array(wv)\n",
    "    print(len(vocab), wv.shape, len(w2i))\n",
    "    \n",
    "    return wv, w2i, vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000000 (3000000, 300) 3000000\n",
      "3000000 (3000000, 300) 3000000\n"
     ]
    }
   ],
   "source": [
    "file_path_wv = './data/GoogleNews-vectors-negative300.bin'\n",
    "file_path_hd = './data/GoogleNews-vectors-negative300-hard-debiased.bin'\n",
    "\n",
    "wv, w2i, vocab = load_w2v(file_path_wv)\n",
    "hd_wv, hd_w2i, hd_vocab = load_w2v(file_path_hd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000000, 300)\n"
     ]
    }
   ],
   "source": [
    "def load_glove_p(path):\n",
    "    # Modified from original because we did not pickle a map but rather wv_f directly\n",
    "    wv = pickle.load(open(path, 'rb'))\n",
    "    print(wv.shape)\n",
    "    return wv\n",
    "dhd_wv = load_glove_p(\"./data/dhd_word2vec_reproduce.p\")\n",
    "dhd_w2i = w2i\n",
    "dhd_vocab = vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simi(a, b):\n",
    "    return 1-scipy.spatial.distance.cosine(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analogy & Concept Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results may vary a bit if you change the algorithm in function \"evaluate_categorization\" in eval.py\n",
    "from eval import evaluate_cate, evaluate_ana, evaluate_analogy_google, evaluate_analogy_msr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating categorization benchmarks\n",
      "Sample data from AP, num of samples: 402 : \"['acceptance']\" is assigned class legal_document\n",
      "exist 397 in 402\n",
      "Cluster purity on AP 0.6448362720403022\n",
      "Sample data from ESSLI_2c, num of samples: 45 : \"['run']\" is assigned class motionManner-motion\n",
      "exist 45 in 45\n",
      "Cluster purity on ESSLI_2c 0.6444444444444445\n",
      "Sample data from ESSLI_2b, num of samples: 40 : \"['chicken']\" is assigned class HI\n",
      "exist 40 in 40\n",
      "Cluster purity on ESSLI_2b 0.8\n",
      "Sample data from ESSLI_1a, num of samples: 44 : \"['boat']\" is assigned class vehicle-artifact\n",
      "exist 44 in 44\n",
      "Cluster purity on ESSLI_1a 0.75\n",
      "Sample data from Battig, num of samples: 5231 : \"knife\" is assigned class weapon\n",
      "exist 3957 in 5231\n",
      "Cluster purity on Battig 0.4627242860753095\n",
      "Sample data from BLESS, num of samples: 200 : \"['bomb']\" is assigned class weapon\n",
      "exist 199 in 200\n",
      "Cluster purity on BLESS 0.7889447236180904\n"
     ]
    }
   ],
   "source": [
    "evaluate_cate(wv, w2i, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating categorization benchmarks\n",
      "Sample data from AP, num of samples: 402 : \"['acceptance']\" is assigned class legal_document\n",
      "exist 397 in 402\n",
      "Cluster purity on AP 0.7052896725440806\n",
      "Sample data from ESSLI_2c, num of samples: 45 : \"['run']\" is assigned class motionManner-motion\n",
      "exist 45 in 45\n",
      "Cluster purity on ESSLI_2c 0.6444444444444445\n",
      "Sample data from ESSLI_2b, num of samples: 40 : \"['chicken']\" is assigned class HI\n",
      "exist 40 in 40\n",
      "Cluster purity on ESSLI_2b 0.8\n",
      "Sample data from ESSLI_1a, num of samples: 44 : \"['boat']\" is assigned class vehicle-artifact\n",
      "exist 44 in 44\n",
      "Cluster purity on ESSLI_1a 0.7954545454545455\n",
      "Sample data from Battig, num of samples: 5231 : \"knife\" is assigned class weapon\n",
      "exist 3957 in 5231\n"
     ]
    }
   ],
   "source": [
    "evaluate_cate(hd_wv, hd_w2i, hd_vocab)\n",
    "evaluate_cate(dhd_wv, dhd_w2i, dhd_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from utils import limit_vocab\n",
    "\n",
    "gender_specific = []\n",
    "\n",
    "with open('./data/male_word_file.txt') as f:\n",
    "    for l in f:\n",
    "        gender_specific.append(l.strip())\n",
    "with open('./data/female_word_file.txt') as f:\n",
    "    for l in f:\n",
    "        gender_specific.append(l.strip())\n",
    "print(len(gender_specific))\n",
    "\n",
    "with codecs.open('./data/gender_specific_full.json') as f:\n",
    "    gender_specific.extend(json.load(f))\n",
    "with codecs.open('./data/definitional_pairs.json') as f:\n",
    "    definitional_pairs = json.load(f)\n",
    "with codecs.open('./data/equalize_pairs.json') as f:\n",
    "    equalize_pairs = json.load(f)\n",
    "\n",
    "exclude_words = gender_specific\n",
    "print(len(exclude_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import limit_vocab\n",
    "# create spaces of limited vocabulary\n",
    "wv_vocab_limit, wv_limit, wv_w2i_limit = limit_vocab(wv, w2i, vocab, exclude = exclude_words)\n",
    "hd_vocab_limit, hd_limit, hd_w2i_limit = limit_vocab(\n",
    "    hd_wv, hd_w2i, hd_vocab, exclude = exclude_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dhd_vocab_limit, dhd_limit, dhd_w2i_limit = limit_vocab(\n",
    "    dhd_wv, dhd_w2i, dhd_vocab, exclude = exclude_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select top biased words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_embed = wv[w2i['he'], :]\n",
    "she_embed = wv[w2i['she'], :]\n",
    "\n",
    "def simi(a, b):\n",
    "    return 1-scipy.spatial.distance.cosine(a, b)\n",
    "\n",
    "def compute_bias_by_projection(wv, w2i, vocab):\n",
    "    d = {}\n",
    "    for w in vocab:\n",
    "        u = wv[w2i[w], :]\n",
    "        d[w] = simi(u, he_embed) - simi(u, she_embed)\n",
    "    return d\n",
    "\n",
    "gender_bias_bef = compute_bias_by_projection(wv_limit, wv_w2i_limit, wv_vocab_limit)\n",
    "sorted_g = sorted(gender_bias_bef.items(), key=operator.itemgetter(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE visualization of originally top biased words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(vectors, y_true, y_pred, ax, title, random_state):\n",
    "    \n",
    "    # perform TSNE\n",
    "    vectors = normalize(vectors)\n",
    "    X_embedded = TSNE(n_components=2, random_state=random_state).fit_transform(vectors)\n",
    "    for x,p,y in zip(X_embedded, y_pred, y_true):\n",
    "        if y:\n",
    "            ax.scatter(x[0], x[1], marker = '.', c = 'c')\n",
    "        else:\n",
    "            ax.scatter(x[0], x[1], marker = 'x', c = 'darkviolet')\n",
    "    \n",
    "    return ax\n",
    "\n",
    "def cluster_and_visualize(words, X1, title, random_state, tsne_random_state, y_true, num=2):\n",
    "    \n",
    "    kmeans_1 = KMeans(n_clusters=num, random_state=random_state).fit(X1)\n",
    "    y_pred_1 = kmeans_1.predict(X1)\n",
    "    correct = [1 if item1 == item2 else 0 for (item1,item2) in zip(y_true, y_pred_1) ]\n",
    "    print('precision', max(sum(correct)/float(len(correct)), 1 - sum(correct)/float(len(correct))))\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 1, figsize=(6, 3))\n",
    "    ax1 = visualize(X1, y_true, y_pred_1, axs, title, tsne_random_state)\n",
    "    \n",
    "#     fig.savefig(\"a_{}_{}_{}.pdf\".format(title, size, random_state))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from utils import extract_vectors\n",
    "import operator\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler\n",
    "%matplotlib inline\n",
    "\n",
    "size=500\n",
    "female = [item[0] for item in sorted_g[:size]]\n",
    "male = [item[0] for item in sorted_g[-size:]]\n",
    "y_true = [1]*size + [0]*size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may change the random states to get more visualization result\n",
    "random_state = 0\n",
    "tsne_random_state = 2\n",
    "cluster_and_visualize(male + female, extract_vectors(male + female, wv_limit, wv_w2i_limit), \n",
    "                          'Word2Vec', random_state, tsne_random_state, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_and_visualize(male + female, extract_vectors(male + female, hd_limit, hd_w2i_limit), \n",
    "                          'Hard Word2Vec', random_state, tsne_random_state, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_and_visualize(male + female, extract_vectors(male + female, dhd_limit, dhd_w2i_limit), \n",
    "                          'Double-Hard Word2Vec', random_state, tsne_random_state, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster originally top biased words\n",
    "Following results may be slightly different from the numbers reported in the paper. This is due to:\n",
    "\n",
    "1. how we select top biased words. Here, we select ones with largest similarities with **he** and **she** without normalizing embeddings, however, this may not be the perfect way. Other options can be:\n",
    "    - normalize word embeddings first and then pick top biased words.\n",
    "    - select according to projections on the difference vector of **he** and **she**.\n",
    "2. different random state used in the clustering algorithm.\n",
    "\n",
    "We care more about the relative clustering acc change and we see significant decrease with Double-Hard Debiased embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster(words, X1, random_state, y_true, num=2):\n",
    "    \n",
    "    kmeans_1 = KMeans(n_clusters=num, random_state=random_state).fit(X1)\n",
    "    y_pred_1 = kmeans_1.predict(X1)\n",
    "    correct = [1 if item1 == item2 else 0 for (item1,item2) in zip(y_true, y_pred_1) ]\n",
    "    print('precision', max(sum(correct)/float(len(correct)), 1 - sum(correct)/float(len(correct))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster most biased words before and after debiasing\n",
    "\n",
    "def my_cluster(wv, w2i, start=0, size=500, random_state = 1):\n",
    "    \n",
    "    if start == 0:\n",
    "        female = [item[0] for item in sorted_g[:size]]\n",
    "        male = [item[0] for item in sorted_g[-size:]]\n",
    "    else:\n",
    "        female = [item[0] for item in sorted_g[start:size+start]]\n",
    "        male = [item[0] for item in sorted_g[-(start+size):-start]]\n",
    "\n",
    "    y_true = [1]*size + [0]*size\n",
    "    \n",
    "    cluster(male + female, extract_vectors(male + female, wv, w2i), random_state, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state_=3\n",
    "start=0\n",
    "end=100\n",
    "my_cluster(wv_limit, wv_w2i_limit, start, end, random_state=random_state_)\n",
    "my_cluster(hd_limit, hd_w2i_limit, start, end, random_state=random_state_)\n",
    "my_cluster(dhd_limit, dhd_w2i_limit, start, end, random_state=random_state_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state_=4\n",
    "start=0\n",
    "end=500\n",
    "my_cluster(wv_limit, wv_w2i_limit, start, end, random_state=random_state_)\n",
    "my_cluster(hd_limit, hd_w2i_limit, start, end, random_state=random_state_)\n",
    "my_cluster(dhd_limit, dhd_w2i_limit, start, end, random_state=random_state_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state_=1\n",
    "start=0\n",
    "end=1000\n",
    "my_cluster(wv_limit, wv_w2i_limit, start, end, random_state=random_state_)\n",
    "my_cluster(hd_limit, hd_w2i_limit, start, end, random_state=random_state_)\n",
    "my_cluster(dhd_limit, dhd_w2i_limit, start, end, random_state=random_state_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification experiment\n",
    "\n",
    "We also test classification experiment as described in [Lipstick on a Pig](https://arxiv.org/abs/1903.03862). However, we don't see any significant improvement on any debiasing approaches. We suspect that classification may not reflect gender bia correctly as it can always find a decision boundary with supervisions which may not be gender. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from random import shuffle\n",
    "import random\n",
    "from utils import train_and_predict\n",
    "\n",
    "def cls(wv, w2i, vocab, size_train, size_test):\n",
    "    size = size_train + size_test\n",
    "    females = [item[0] for item in sorted_g[:size]]\n",
    "    males = [item[0] for item in sorted_g[-size:]]\n",
    "    males.reverse()\n",
    "\n",
    "    shuffle(females)\n",
    "    shuffle(males)\n",
    "\n",
    "    train_and_predict(wv, w2i, vocab, size_train, size_test, males, females)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_train=100\n",
    "size_test=1000\n",
    "cls(wv_limit, wv_w2i_limit, wv_vocab_limit, size_train, size_test)\n",
    "cls(hd_limit, hd_w2i_limit, hd_vocab_limit, size_train, size_test)\n",
    "cls(dhd_limit, dhd_w2i_limit, dhd_vocab_limit, size_train, size_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_train=100\n",
    "size_test=2000\n",
    "cls(wv_limit, wv_w2i_limit, wv_vocab_limit, size_train, size_test)\n",
    "cls(hd_limit, hd_w2i_limit, hd_vocab_limit, size_train, size_test)\n",
    "cls(dhd_limit, dhd_w2i_limit, dhd_vocab_limit, size_train, size_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association Experiments (Calisken et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import p_value_exhust, effect_size\n",
    "from utils import WEAT_words\n",
    "\n",
    "A = WEAT_words['A']\n",
    "B = WEAT_words['B']\n",
    "C = WEAT_words['C']\n",
    "D = WEAT_words['D']\n",
    "E = WEAT_words['E']\n",
    "F = WEAT_words['F']\n",
    "G = WEAT_words['G']\n",
    "H = WEAT_words['H']\n",
    "A = [elem for elem in A]\n",
    "B = [elem for elem in B]\n",
    "C = [elem for elem in C]\n",
    "D = [elem for elem in D]\n",
    "E = [elem for elem in E]\n",
    "F = [elem for elem in F]\n",
    "G = [elem for elem in G]\n",
    "H = [elem for elem in H]\n",
    "print(effect_size(A, B, C, D, wv, w2i, vocab))\n",
    "print(effect_size(A, B, C, D, hd_wv, hd_w2i, hd_vocab))\n",
    "print(effect_size(A, B, C, D, dhd_wv, dhd_w2i, dhd_vocab))\n",
    "print(p_value_exhust(A, B, C, D, wv, w2i, vocab))\n",
    "print(p_value_exhust(A, B, C, D, hd_wv, hd_w2i, hd_vocab))\n",
    "print(p_value_exhust(A, B, C, D, dhd_wv, dhd_w2i, dhd_vocab))\n",
    "print(effect_size(A, B, E, F, wv, w2i, vocab))\n",
    "print(effect_size(A, B, E, F, hd_wv, hd_w2i, hd_vocab))\n",
    "print(effect_size(A, B, E, F, dhd_wv, dhd_w2i, dhd_vocab))\n",
    "print(p_value_exhust(A, B, E, F, wv, w2i, vocab))\n",
    "print(p_value_exhust(A, B, E, F, hd_wv, hd_w2i, hd_vocab))\n",
    "print(p_value_exhust(A, B, E, F, dhd_wv, dhd_w2i, dhd_vocab))\n",
    "print(effect_size(A, B, G, H, wv, w2i, vocab))\n",
    "print(effect_size(A, B, G, H, hd_wv, hd_w2i, hd_vocab))\n",
    "print(effect_size(A, B, G, H, dhd_wv, dhd_w2i, dhd_vocab))\n",
    "print(p_value_exhust(A, B, G, H, wv, w2i, vocab))\n",
    "print(p_value_exhust(A, B, G, H, hd_wv, hd_w2i, hd_vocab))\n",
    "print(p_value_exhust(A, B, G, H, dhd_wv, dhd_w2i, dhd_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(effect_size(A, B, C, D, wv, w2i, vocab))\n",
    "print(effect_size(A, B, C, D, hd_wv, hd_w2i, hd_vocab))\n",
    "print(effect_size(A, B, C, D, dhd_wv, dhd_w2i, dhd_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(p_value_exhust(A, B, C, D, wv, w2i, vocab))\n",
    "print(p_value_exhust(A, B, C, D, hd_wv, hd_w2i, hd_vocab))\n",
    "print(p_value_exhust(A, B, C, D, dhd_wv, dhd_w2i, dhd_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
